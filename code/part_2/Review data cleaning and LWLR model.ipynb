{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langdetect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from pandas import DataFrame,Series\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import string\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from translate import Translator\n",
    "from langdetect import detect\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pizza Hut</td>\n",
       "      <td>[320, 'Restaurants, Italian, Pizza, Fast Food,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Domino's Pizza</td>\n",
       "      <td>[209, 'Pizza, Caterers, Restaurants, Event Pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Papa John's Pizza</td>\n",
       "      <td>[152, 'Pizza, Restaurants', 'Tempe', 'AZ']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Little Caesars Pizza</td>\n",
       "      <td>[112, 'Restaurants, Pizza', 'Whitchurch-Stouff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pizza Pizza</td>\n",
       "      <td>[102, 'Pizza, Restaurants, Italian, Chicken Wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Boston Pizza</td>\n",
       "      <td>[69, 'Pubs, Pizza, American (Traditional), Nig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Papa Murphy's</td>\n",
       "      <td>[68, 'Restaurants, Pizza', 'Phoenix', 'AZ']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Marco's Pizza</td>\n",
       "      <td>[52, 'Italian, Restaurants, Pizza, Chicken Win...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pizza Nova</td>\n",
       "      <td>[52, 'Restaurants, Pizza', 'Richmond Hill', 'ON']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Hungry Howie's Pizza</td>\n",
       "      <td>[40, 'Restaurants, Pizza', 'Charlotte', 'NC']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name                                               info\n",
       "1              Pizza Hut  [320, 'Restaurants, Italian, Pizza, Fast Food,...\n",
       "2         Domino's Pizza  [209, 'Pizza, Caterers, Restaurants, Event Pla...\n",
       "3      Papa John's Pizza         [152, 'Pizza, Restaurants', 'Tempe', 'AZ']\n",
       "4   Little Caesars Pizza  [112, 'Restaurants, Pizza', 'Whitchurch-Stouff...\n",
       "5            Pizza Pizza  [102, 'Pizza, Restaurants, Italian, Chicken Wi...\n",
       "6           Boston Pizza  [69, 'Pubs, Pizza, American (Traditional), Nig...\n",
       "7          Papa Murphy's        [68, 'Restaurants, Pizza', 'Phoenix', 'AZ']\n",
       "8          Marco's Pizza  [52, 'Italian, Restaurants, Pizza, Chicken Win...\n",
       "9             Pizza Nova  [52, 'Restaurants, Pizza', 'Richmond Hill', 'ON']\n",
       "10  Hungry Howie's Pizza      [40, 'Restaurants, Pizza', 'Charlotte', 'NC']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Top10 Pizza restaurants based on the count of the restaurants \n",
    "# info includes number of restaurants and its corresponding category\n",
    "pizzatop10=pd.read_csv(\"Pizzatop10count.csv\",names=[\"number\",\"name\",\"info\"])[[\"name\",\"info\"]][1:]\n",
    "pizzatop10\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394428"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All pizza restaurants' reviews\n",
    "reviewall=pd.read_csv(\"pizza_review.csv\")\n",
    "len(reviewall['review_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>267</td>\n",
       "      <td>267</td>\n",
       "      <td>fweCYi8FmbJXHCqLnwuk8w</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-06-27 23:35:47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PnKm8y0thZ5ZdWhuOk7Opg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Hands down, this is the best pizza place in Me...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>VJvQiGrmtFXAmswRRIWYYw</td>\n",
       "      <td>Marco's Pizza</td>\n",
       "      <td>[52, 'Italian, Restaurants, Pizza, Chicken Win...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>600</td>\n",
       "      <td>600</td>\n",
       "      <td>pif8Io-Jn2veckVGzkEyJw</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-11-14 01:01:56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bLgMDEj1EXOuZ_94P5I7jA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I've never had a bad experience here.\\r\\r\\n\\r\\...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>renPzRDqMZpMaHiCD_e1_A</td>\n",
       "      <td>Pizza Hut</td>\n",
       "      <td>[320, 'Restaurants, Italian, Pizza, Fast Food,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>751</td>\n",
       "      <td>751</td>\n",
       "      <td>C2skZUb7BLpv3e78Mcf5cA</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-09-03 01:40:55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5haHR9yvGIUQ-sFMrAzsQQ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>We order from this Pizza Hut often and always ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>txHu-M3p2tLKSpNGMWUO0Q</td>\n",
       "      <td>Pizza Hut</td>\n",
       "      <td>[320, 'Restaurants, Italian, Pizza, Fast Food,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Unnamed: 0.1             business_id  cool  \\\n",
       "18         267           267  fweCYi8FmbJXHCqLnwuk8w     0   \n",
       "32         600           600  pif8Io-Jn2veckVGzkEyJw     0   \n",
       "38         751           751  C2skZUb7BLpv3e78Mcf5cA     0   \n",
       "\n",
       "                   date  funny               review_id  stars  \\\n",
       "18  2017-06-27 23:35:47    0.0  PnKm8y0thZ5ZdWhuOk7Opg    5.0   \n",
       "32  2013-11-14 01:01:56    1.0  bLgMDEj1EXOuZ_94P5I7jA    4.0   \n",
       "38  2018-09-03 01:40:55    0.0  5haHR9yvGIUQ-sFMrAzsQQ    1.0   \n",
       "\n",
       "                                                 text  useful  \\\n",
       "18  Hands down, this is the best pizza place in Me...     0.0   \n",
       "32  I've never had a bad experience here.\\r\\r\\n\\r\\...     0.0   \n",
       "38  We order from this Pizza Hut often and always ...     0.0   \n",
       "\n",
       "                   user_id           name  \\\n",
       "18  VJvQiGrmtFXAmswRRIWYYw  Marco's Pizza   \n",
       "32  renPzRDqMZpMaHiCD_e1_A      Pizza Hut   \n",
       "38  txHu-M3p2tLKSpNGMWUO0Q      Pizza Hut   \n",
       "\n",
       "                                                 info  \n",
       "18  [52, 'Italian, Restaurants, Pizza, Chicken Win...  \n",
       "32  [320, 'Restaurants, Italian, Pizza, Fast Food,...  \n",
       "38  [320, 'Restaurants, Italian, Pizza, Fast Food,...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the corresponding top10 restaurants' review\n",
    "reviewall['info']=reviewall['name'].map(pizzatop10.set_index('name')['info'])\n",
    "reviewtop10=reviewall.loc[reviewall['info'].isin(list(pizzatop10['info']))]\n",
    "reviewtop10[:3]  #Only show the first 3 lines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17951"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviewtop10)  #Total number of reviews for top 10 pizza chain restaurants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "      <th>name</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Hands down, this is the best pizza place in Me...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Marco's Pizza</td>\n",
       "      <td>VJvQiGrmtFXAmswRRIWYYw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>I've never had a bad experience here.\\r\\r\\n\\r\\...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Pizza Hut</td>\n",
       "      <td>renPzRDqMZpMaHiCD_e1_A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>We order from this Pizza Hut often and always ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Pizza Hut</td>\n",
       "      <td>txHu-M3p2tLKSpNGMWUO0Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  stars           name  \\\n",
       "18  Hands down, this is the best pizza place in Me...    5.0  Marco's Pizza   \n",
       "32  I've never had a bad experience here.\\r\\r\\n\\r\\...    4.0      Pizza Hut   \n",
       "38  We order from this Pizza Hut often and always ...    1.0      Pizza Hut   \n",
       "\n",
       "                   user_id  \n",
       "18  VJvQiGrmtFXAmswRRIWYYw  \n",
       "32  renPzRDqMZpMaHiCD_e1_A  \n",
       "38  txHu-M3p2tLKSpNGMWUO0Q  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reviewinfo includes the review text, the stars, the pizza restaurant name and the user_id of that review\n",
    "reviewinfo=reviewtop10[[\"text\",\"stars\",\"name\",\"user_id\"]]\n",
    "reviewinfo[:3]  #Only show the first 3 lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18    Hands down, this is the best pizza place in Me...\n",
       "32    I've never had a bad experience here.\\r\\r\\n\\r\\...\n",
       "38    We order from this Pizza Hut often and always ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get only the text part\n",
    "reviewtext=reviewtop10[\"text\"]\n",
    "reviewtext[:3]  #Only show the first 3 lines\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate different languages into English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "language=[]\n",
    "for review in reviewtext:\n",
    "    language.append(detect(review))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'af', 'da', 'en', 'es', 'fr', 'hr', 'it', 'pt', 'sk', 'so', 'sw'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(language)  ##Language types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do review translation\n",
    "translatereview=[]\n",
    "for review in reviewtext:\n",
    "    languagetype=detect(review)\n",
    "    if languagetype=='en':\n",
    "        translatereview.append(review)\n",
    "    else:\n",
    "        if languagetype=='af':\n",
    "            lang='Afrikaans'\n",
    "            translator= Translator(from_lang=lang,to_lang=\"english\")\n",
    "            translation = translator.translate(review)\n",
    "            translatereview.append(translation)\n",
    "        elif languagetype=='de':\n",
    "            lang='German'\n",
    "            translator= Translator(from_lang=lang,to_lang=\"english\")\n",
    "            translation = translator.translate(review)\n",
    "            translatereview.append(translation)\n",
    "        elif languagetype=='da':\n",
    "            lang='Danish'\n",
    "            translator= Translator(from_lang=lang,to_lang=\"english\")\n",
    "            translation = translator.translate(review)\n",
    "            translatereview.append(translation)\n",
    "        elif languagetype=='es':\n",
    "            lang='spanish'\n",
    "            translator= Translator(from_lang=lang,to_lang=\"english\")\n",
    "            translation = translator.translate(review)\n",
    "            translatereview.append(translation)\n",
    "        elif languagetype=='et':\n",
    "            lang='estonian'\n",
    "            translator= Translator(from_lang=lang,to_lang=\"english\")\n",
    "            translation = translator.translate(review)\n",
    "            translatereview.append(translation)\n",
    "        elif languagetype=='fr':\n",
    "            lang='french'\n",
    "            translator= Translator(from_lang=lang,to_lang=\"english\")\n",
    "            translation = translator.translate(review)\n",
    "            translatereview.append(translation)\n",
    "        elif languagetype=='hr':\n",
    "            lang='croatian'\n",
    "            translator= Translator(from_lang=lang,to_lang=\"english\")\n",
    "            translation = translator.translate(review)\n",
    "            translatereview.append(translation)\n",
    "        elif languagetype=='it':\n",
    "            lang='italian'\n",
    "            translator= Translator(from_lang=lang,to_lang=\"english\")\n",
    "            translation = translator.translate(review)\n",
    "            translatereview.append(translation)\n",
    "        elif languagetype=='pl':\n",
    "            lang='polish'\n",
    "            translator= Translator(from_lang=lang,to_lang=\"english\")\n",
    "            translation = translator.translate(review)\n",
    "            translatereview.append(translation)\n",
    "        elif languagetype=='pt':\n",
    "            lang='portuguese'\n",
    "            translator= Translator(from_lang=lang,to_lang=\"english\")\n",
    "            translation = translator.translate(review)\n",
    "            translatereview.append(translation)\n",
    "        elif languagetype=='sk':\n",
    "            lang='slovak'\n",
    "            translator= Translator(from_lang=lang,to_lang=\"english\")\n",
    "            translation = translator.translate(review)\n",
    "            translatereview.append(translation)\n",
    "        elif languagetype=='so':\n",
    "            lang='somali'\n",
    "            translator= Translator(from_lang=lang,to_lang=\"english\")\n",
    "            translation = translator.translate(review)\n",
    "            translatereview.append(translation)\n",
    "        elif languagetype=='sw':\n",
    "            lang='swahili'\n",
    "            translator= Translator(from_lang=lang,to_lang=\"english\")\n",
    "            translation = translator.translate(review)\n",
    "            translatereview.append(translation)\n",
    "        else:\n",
    "            translatereview.append(review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftranslate=DataFrame(translatereview)\n",
    "dftranslate.to_csv('translate.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Hands down, this is the best pizza place in Me...\n",
       "1    I've never had a bad experience here.\\r\\r\\n\\r\\...\n",
       "2    We order from this Pizza Hut often and always ...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transreview=pd.read_csv('translate.csv')[\"0\"]\n",
    "transreview[:3] #Show only the first three lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>stars</th>\n",
       "      <th>name</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hands down, this is the best pizza place in Me...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Marco's Pizza</td>\n",
       "      <td>VJvQiGrmtFXAmswRRIWYYw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I've never had a bad experience here.\\r\\r\\n\\r\\...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Pizza Hut</td>\n",
       "      <td>renPzRDqMZpMaHiCD_e1_A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We order from this Pizza Hut often and always ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Pizza Hut</td>\n",
       "      <td>txHu-M3p2tLKSpNGMWUO0Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  stars           name  \\\n",
       "0  Hands down, this is the best pizza place in Me...    5.0  Marco's Pizza   \n",
       "1  I've never had a bad experience here.\\r\\r\\n\\r\\...    4.0      Pizza Hut   \n",
       "2  We order from this Pizza Hut often and always ...    1.0      Pizza Hut   \n",
       "\n",
       "                  user_id  \n",
       "0  VJvQiGrmtFXAmswRRIWYYw  \n",
       "1  renPzRDqMZpMaHiCD_e1_A  \n",
       "2  txHu-M3p2tLKSpNGMWUO0Q  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Merge the translated review with the other information like stars, name and user_id\n",
    "transreview1=DataFrame(transreview)\n",
    "transreview1[\"stars\"]=reviewinfo[\"stars\"].values\n",
    "transreview1[\"name\"]=reviewinfo[\"name\"].values\n",
    "transreview1[\"user_id\"]=reviewinfo[\"user_id\"].values\n",
    "transreview1[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "transreview1.to_csv('translateinfo.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>stars</th>\n",
       "      <th>name</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hands down, this is the best pizza place in Me...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Marco's Pizza</td>\n",
       "      <td>VJvQiGrmtFXAmswRRIWYYw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I've never had a bad experience here.\\r\\r\\n\\r\\...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Pizza Hut</td>\n",
       "      <td>renPzRDqMZpMaHiCD_e1_A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We order from this Pizza Hut often and always ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Pizza Hut</td>\n",
       "      <td>txHu-M3p2tLKSpNGMWUO0Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  stars           name  \\\n",
       "0  Hands down, this is the best pizza place in Me...    5.0  Marco's Pizza   \n",
       "1  I've never had a bad experience here.\\r\\r\\n\\r\\...    4.0      Pizza Hut   \n",
       "2  We order from this Pizza Hut often and always ...    1.0      Pizza Hut   \n",
       "\n",
       "                  user_id  \n",
       "0  VJvQiGrmtFXAmswRRIWYYw  \n",
       "1  renPzRDqMZpMaHiCD_e1_A  \n",
       "2  txHu-M3p2tLKSpNGMWUO0Q  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transinfo=pd.read_csv('translateinfo.csv')[['0','stars','name','user_id']]\n",
    "transinfo[:3] ##Show only first 3 lines as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Get userweight we computed from userweight.csv\n",
    "userweight=pd.read_csv(\"userweight.csv\")[['user_id','weight']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the translated review with the corresponding user weight\n",
    "transinfo['weight']=transinfo['user_id'].map(userweight.set_index('user_id')['weight'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Get the translated review text\n",
    "reviewtext=transinfo['0']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Review to sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change each review into sentences, finally we get a list of list, each list include the sentences of one review\n",
    "def text_to_sentence(textdf):\n",
    "    textlist=textdf.tolist()\n",
    "    sentencelist=[]\n",
    "    for review in textlist:\n",
    "        sentences=sent_tokenize(review)\n",
    "        sentencelist.append(sentences)\n",
    "    return sentencelist\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hands down, this is the best pizza place in Mentor!',\n",
       " 'Their pizza is so delicious that the smell alone is enough to make you drool!',\n",
       " 'The cheesy bread is soft and cheesy and just goodness.',\n",
       " 'The pizza is good for leftovers and the next day.',\n",
       " 'The service and staff is very friendly.',\n",
       " '5 stars for sure!']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pizza10sent=text_to_sentence(transreview)\n",
    "pizza10sent[0]  #Show only the first review after sentence breaking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the basic if suggestions raised by the customers for top10 pizza restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the if sentences, these sentences might be the condition and suggestion from the customer directly to Pizza Hut and customer.\n",
    "#Eg: if you're going to a pizza hut in this area, i recommend this one\n",
    "#Eg: if they were not up for delivering that late, a curiosity call would be great so i don't sit at home hungry.\n",
    "def find_if_suggestion(text):\n",
    "    suggestion=[]\n",
    "    for review in text:\n",
    "        for sentence in review:\n",
    "            sentence=sentence.lower()\n",
    "            if 'if ' in sentence or 'If ' in sentence or 'IF ' in sentence or 'iF ' in sentence:\n",
    "                suggestion.append(sentence)\n",
    "    return suggestion\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['if it was a busy night, this would all be more understandable but it was so dead in that restaurant.',\n",
       " 'it took a while for our server to figure out if we can pay with a gift card and cash or not.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pizza10_suggestion=find_if_suggestion(pizza10sent)\n",
    "pizza10_suggestion[5:7] ##Show only 2 suggestions as example  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5753"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pizza10_suggestion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stopwords1=stop_words[:(stop_words.index('very')+1)] #these stopwords include pronowns and positive helping verbs.\n",
    "stopwords1=stopwords1+[\"i've\"]                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First step  top 10 pizza data cleaning mainly deal with pronowns and helping verbs (stopwords1)\n",
    "def pizza10clean1(text):\n",
    "    pizza10clean=[]\n",
    "    for review in text:\n",
    "        s=[]\n",
    "        for sentence in review:\n",
    "            sentence = sentence.lower()\n",
    "            if 'if' not in sentence:\n",
    "                sentence = re.sub('not only (\\w+?), but also', '\\\\1 and ', sentence) # change not only but also to and structure\n",
    "                sentence=sentence.split(\" \")\n",
    "                sentence=[x for x in sentence if not x.strip() in stopwords1] #delete pronowns and helping verbs\n",
    "                sentence=\" \".join(sentence)\n",
    "                s.append(sentence)\n",
    "        pizza10clean.append(s)\n",
    "    return pizza10clean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pizza10sent1=pizza10clean1(pizza10sent)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['here', 'always', 'usually', 'often', 'me', 'im', 'is', 'are', 'was', 'were', 'do', 'did', 'have', 'will', 'it']\n"
     ]
    }
   ],
   "source": [
    "#Some other stopwords like frequency words and again the positive helping verbs\n",
    "stopwords2=['here']+['always']+['usually']+['often']+['me']+['im']+['is']+['are']+['was']+['were']+['do']+['did']+['have']+['will']+['it']\n",
    "print(stopwords2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function deal with negative words and connect them with the verbs behind it and then again delete those \n",
    "#positive helping verbs and some other useless frequency verbs\n",
    "def pizza10clean2(text):\n",
    "    pizza10clean=[]\n",
    "    for review in text:\n",
    "        s=[]\n",
    "        for sentence in review:\n",
    "            sentence = re.sub('n\\'t\\s', ' not', sentence)\n",
    "            sentence = re.sub('not\\s', ' not', sentence) #change not great to notgreat\n",
    "            sentence = re.sub('never\\s',' never',sentence) \n",
    "            sentence = re.sub('nothing\\s',' nothing',sentence)\n",
    "            sentence=sentence.translate(str.maketrans({key: None for key in string.punctuation})) #delete punctuation marks\n",
    "            sentence=sentence.split(\" \")\n",
    "            sentence=[x for x in sentence if not x.strip() in stopwords2]\n",
    "            for i in range (len(sentence)-1):\n",
    "                if sentence[i].strip().startswith(\"not\"):\n",
    "                    sentence[i]=sentence[i]+sentence[i+1] #connect notgreat pizza into notgreatpizza\n",
    "                    sentence[i+1]=\"\"\n",
    "            sentence=\" \".join(sentence)\n",
    "            s.append(sentence)\n",
    "        pizza10clean.append(s)\n",
    "    return pizza10clean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hands down best pizza place mentor',\n",
       "  'pizza delicious smell alone enough make drool',\n",
       "  'cheesy bread soft cheesy just goodness',\n",
       "  'pizza good leftovers next day',\n",
       "  'service staff friendly',\n",
       "  '5 stars sure'],\n",
       " [' neverbad experience',\n",
       "  'delivery pickup whatever food turns good',\n",
       "  'yesterday saving grace papa johns let severely',\n",
       "  'pizza hut quoted hourish wait time which fine know promised 3040 minutes ends hour like pjs wasand house piping hot delicous pizza 25 minutes',\n",
       "  'love']]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pizza10sent2=pizza10clean2(pizza10sent1)\n",
    "pizza10sent2[0:2] ##Show first 2 reviews as example after data cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['Hands down, this is the best pizza place in Mentor!',\n",
       "   'Their pizza is so delicious that the smell alone is enough to make you drool!',\n",
       "   'The cheesy bread is soft and cheesy and just goodness.',\n",
       "   'The pizza is good for leftovers and the next day.',\n",
       "   'The service and staff is very friendly.',\n",
       "   '5 stars for sure!'],\n",
       "  5.0,\n",
       "  \"Marco's Pizza\",\n",
       "  'VJvQiGrmtFXAmswRRIWYYw',\n",
       "  0.000275388635426039),\n",
       " ([\"I've never had a bad experience here.\",\n",
       "   'delivery, pickup, whatever, the food always turns out good, for me.',\n",
       "   \"Yesterday they were my saving grace, when Papa John's let me down SEVERELY.\",\n",
       "   \"Pizza Hut quoted me an hour-ish wait time (which is fine when I know about it, not when i'm promised 30-40 minutes and it ends up being over an hour like PJ's was)...and they were there at my house with my piping hot, delicous pizza in about 25 minutes.\",\n",
       "   'LOVE.'],\n",
       "  4.0,\n",
       "  'Pizza Hut',\n",
       "  'renPzRDqMZpMaHiCD_e1_A',\n",
       "  0.10796669498067801)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add stars, name ,user_id, userweight to the cleaned translated review text\n",
    "pizza10info=[]\n",
    "for i in range (len(pizza10sent2)):\n",
    "    pizza10info.append((pizza10sent[i],transinfo['stars'][i],transinfo['name'][i],transinfo['user_id'][i],transinfo['weight'][i]))\n",
    "\n",
    "pizza10info[0:2] ##Show first 2 as example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract nown vocabulary for top 10 pizza restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "nown_list = ['NN','NNS','NNPS','NNP']   #https://blog.csdn.net/john159151/article/details/50255101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nown_vocabulary(text):\n",
    "    vocabularylist = []\n",
    "    for review in text:\n",
    "        for sentence in review:\n",
    "            tag = nltk.pos_tag(word_tokenize(sentence))\n",
    "            for i in range(len(tag)):\n",
    "                if tag[i][1] in nown_list:\n",
    "                    vocabularylist.append(tag[i][0])\n",
    "    return vocabularylist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hands',\n",
       " 'place',\n",
       " 'mentor',\n",
       " 'smell',\n",
       " 'drool',\n",
       " 'cheesy',\n",
       " 'bread',\n",
       " 'cheesy',\n",
       " 'goodness',\n",
       " 'leftovers']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nown_vocabulary = find_nown_vocabulary(pizza10sent2)\n",
    "nown_vocabulary[:10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "325318"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nown_vocabulary) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pizza', 24165),\n",
       " ('order', 11138),\n",
       " ('time', 7000),\n",
       " ('service', 5603),\n",
       " ('delivery', 4873)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabularynown = np.array(nown_vocabulary)\n",
    "nown_vocabulary_dict=Counter(vocabularynown)  # {label:sum(label)}\n",
    "nown_vocabulary_dict.most_common(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract adj vocabulary for top 10 Pizza restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_tag = ['JJ','JJR','JJS','RB','RBR','RBS'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_adj_vocabulary(text):\n",
    "    vocabularylist = []\n",
    "    for review in text:\n",
    "        for sentence in review:\n",
    "            tag = nltk.pos_tag(word_tokenize(sentence))\n",
    "            for i in range(len(tag)):\n",
    "                if tag[i][1] in adj_tag:\n",
    "                    vocabularylist.append(tag[i][0])\n",
    "    return vocabularylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_vocabulary = find_adj_vocabulary(pizza10sent2)\n",
    "#adj_vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_vocabulary=[x for x in adj_vocabulary if not x in ['pizza','just']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('good', 5068),\n",
       " ('great', 3173),\n",
       " ('back', 3087),\n",
       " ('really', 2502),\n",
       " ('even', 2310)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabularyadj = np.array(adj_vocabulary)\n",
    "adj_vocabulary_dict=Counter(vocabularyadj)  # {label:sum(label)}\n",
    "adj_vocabulary_dict.most_common(5)   ##TOP 5 most common adjs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract not vocabularies for top 10 Pizza restaurauts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_not_vocabulary(text):\n",
    "    vocabulary=[]\n",
    "    for review in text:\n",
    "        for sentence in review:\n",
    "            sentence=sentence.split(\" \")\n",
    "            sentence=[x for x in sentence if x.startswith(\"not\") or x.startswith(\"never\")]\n",
    "            if sentence!=[]:\n",
    "                vocabulary.append(sentence[0])\n",
    "    return vocabulary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_vocabulary = find_not_vocabulary(pizza10sent2)\n",
    "not_vocabulary=[x for x in not_vocabulary if not x in ['not']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('neverorder', 361),\n",
       " ('neveragain', 170),\n",
       " ('nevergo', 166),\n",
       " ('nothing', 123),\n",
       " ('neverever', 92)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabularynot = np.array(not_vocabulary)\n",
    "not_vocabulary_dict=Counter(vocabularynot)  # {label:sum(label)}\n",
    "not_vocabulary_dict.most_common(5)  ##Top 5 most common not phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjective list (Combine the top 50 \"adjective\" list with top 50 \"not \" list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good', 'great', 'back']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not1=[x[0] for x in not_vocabulary_dict.most_common(50)]\n",
    "adj1=[x[0] for x in adj_vocabulary_dict.most_common(50)]\n",
    "adj_list=adj1+not1\n",
    "adj_list[:3] ## Show only the first 3 for example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gain the feature matrix X and labels y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=[x[1] for x in pizza10info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_y=DataFrame(y)[0].apply(lambda x:1 if x>3 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_weight=[x[4] for x in pizza10info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 3., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the word count matrix(17951*100), row represents each review and column represents each adjective words\n",
    "N=len(pizza10sent2);p=100\n",
    "X=np.zeros([N,p])\n",
    "for i in range(N):\n",
    "    for j in range (p):\n",
    "        for sentence in pizza10sent2[i]:\n",
    "            if sentence.find(adj_list[j])!=-1:\n",
    "                X[i][j]+=1\n",
    "            else:\n",
    "                continue\n",
    "X            \n",
    "X[1] ##Take the second row as an example, this line represents the 100 common adjected words' count frequency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Logistic regression (without userweight adjustment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, binary_y, test_size=0.2, shuffle=True, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=123, solver='sag', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modellr_train = LogisticRegression(random_state=123, solver='sag')\n",
    "modellr_train.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.50311192,  1.29239829, -0.37381768,  0.15336853, -0.32713115,\n",
       "        -0.32223852, -0.44635371,  0.19622809, -0.1765264 ,  0.0838625 ,\n",
       "        -0.06273982,  0.10420632,  0.11398552, -0.48470866, -0.31640739,\n",
       "        -0.18816979, -0.17308946,  1.32511646, -0.52609842, -0.7267471 ,\n",
       "        -0.03048523,  1.11982061, -0.21740408,  0.09373896,  0.62442384,\n",
       "         0.1941665 ,  0.13740169,  0.11841349, -2.93839308, -0.74394121,\n",
       "        -0.10092547,  1.05161534, -0.26477731, -0.15920014, -0.17302249,\n",
       "         0.03915269,  0.91422732, -1.82559428,  0.80205197,  2.02912966,\n",
       "        -0.33712659, -0.71305232, -0.71516834,  0.18259643,  0.16445248,\n",
       "         0.08860237, -0.13589944,  0.0249552 , -2.01216548, -0.94652905,\n",
       "        -0.93123443, -1.69293125, -0.76270352, -0.82389617, -1.63849199,\n",
       "         0.7413609 , -1.01317019,  1.43728708, -0.62028797,  1.49102661,\n",
       "        -0.43683603, -0.19873996, -1.06526174, -0.54102271, -0.56539215,\n",
       "        -0.7537161 , -0.98971899, -0.93814303, -1.38944245, -1.45635463,\n",
       "         1.08916042, -1.48627548, -1.05671929, -1.74058102, -1.29881568,\n",
       "         1.78890636,  1.08973453, -0.03724431, -0.50196684, -1.18698005,\n",
       "        -0.63581845,  0.21748739, -1.0212773 , -1.09315479, -0.00661822,\n",
       "        -0.27326226, -0.06964938, -0.54994318, -0.96556489, -0.79893977,\n",
       "         0.55002695,  0.0891502 , -0.30470122,  0.62585622, -1.0947499 ,\n",
       "        -1.03076282, -0.5488917 ,  1.81919029,  0.68129737, -0.57038495]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modellr_train.coef_  #coefficients of linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.25619604566972"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the logistic model accuracy without user weight adjustment\n",
    "y_pred = modellr_train.predict(X_test)\n",
    "num_correct_predictions = (y_pred == y_test).sum()\n",
    "num_correct_predictions\n",
    "accuracy=(num_correct_predictions / len(y_test)) * 100\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model accuracy is above 80%, which is ok."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression without considering user weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=1, normalize=False)\n",
      "[ 0.80585011  1.36182955  0.01585113  0.23867353  0.027046    0.01989688\n",
      "  0.0094359   0.3795964   0.01545671  0.10245094  0.14042614  0.27070849\n",
      "  0.074725    0.04186619  0.20420194  0.3308061   0.13182834  1.5559086\n",
      "  0.06573307 -0.00844682  0.11194231  1.32953576 -0.01703627  0.1703246\n",
      "  0.82742065  0.11617336  0.20494038  0.20555855  0.01320586  0.04320024\n",
      "  0.17766274  0.80708317  0.06512985 -0.25275775  0.09856874  0.12440467\n",
      "  1.1752582   0.10848658  0.74476522  1.43582896  0.18905354  0.00620309\n",
      " -0.19623573 -0.1066453   0.38185567  0.1048467  -0.03256115  0.17797754\n",
      "  0.10548872 -0.1580932   0.12747072 -0.07510487  0.01448535  0.04946933\n",
      " -0.05403813  0.28310318 -0.09325666  1.26894146  0.18135272  0.91371789\n",
      " -0.09574741 -0.09349543 -0.09025443  0.19521358 -0.2561834   0.09814911\n",
      " -0.2349563   0.03105837 -0.04110311 -0.18677994  0.60584188  0.06216545\n",
      "  0.0311827   0.03501543 -0.22904457  1.48747923  0.79483918  0.18913626\n",
      "  0.1527326  -0.01509829  0.39362707  0.45704157  0.21233939 -0.25481446\n",
      "  0.36374907 -0.28112406  0.10018129 -0.04593851 -0.33207709 -0.25117412\n",
      "  0.53782433 -0.04534432  0.28348519 -0.26351481 -0.21322859  0.28725083\n",
      "  0.16223057  1.56816687 -0.59724538 -0.07918735]\n"
     ]
    }
   ],
   "source": [
    "linreg = LinearRegression(fit_intercept=False)\n",
    "modellm_train=linreg.fit(X_train, y_train)\n",
    "print (modellm_train)\n",
    "print (linreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9343057852506362"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the MSE of this model\n",
    "y_pred = modellm_train.predict(X_test)\n",
    "MSElm=sum((y_pred-y_test)**2)/len(y_test)\n",
    "MSElm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MSE of linear regression model is 3.934."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use full dataset and get the weight(coefficients) of each adjective words without user weight adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression(fit_intercept=False)\n",
    "modellm=linreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm={\"adj\":adj_list,\"lin_reg_weight\":linreg.coef_}\n",
    "weight=DataFrame(data=lm)\n",
    "weight_lmsort=weight.sort_values(by=\"lin_reg_weight\",ascending=False)\n",
    "weight_lmsort.to_csv(\"weight.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression considering user weight (LWLR-local weighted linear regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=1+np.array(user_weight)  #The weight vector is the userweight of each review plus 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test,w_train,w_test = train_test_split(X, y, w,test_size=0.2, shuffle=True, random_state=375)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_train=np.diag(w_train)  #Use the weight from the training set as the diagonal of the training weight matrix\n",
    "W_test=np.diag(w_test)   #Use the weight from the test set as the diagonal of the test weight matrix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following coefficients of LWLR model is generated from this formula $$\\hat \\beta=(X'WX)^{-1}(X'WY)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.80903942,  1.31883608,  0.03958767,  0.2834962 ,  0.04468838,\n",
       "       -0.01523993,  0.0128836 ,  0.42319252,  0.03479355,  0.13298831,\n",
       "        0.15438527,  0.23418133,  0.07660867, -0.0059665 ,  0.17401661,\n",
       "        0.30556473,  0.06817896,  1.51819295,  0.02173437, -0.01729857,\n",
       "        0.15200634,  1.21586978,  0.09980095,  0.19605558,  0.84379385,\n",
       "        0.10424209,  0.16924128,  0.20119745, -0.01797771,  0.06708151,\n",
       "        0.1214455 ,  0.77729401,  0.02791339, -0.35495408,  0.18797074,\n",
       "        0.1468556 ,  1.07123741,  0.13107984,  0.72803473,  1.45598882,\n",
       "        0.22832028,  0.05443304, -0.15675609, -0.07918427,  0.36152144,\n",
       "        0.16980515, -0.03413417,  0.08284363,  0.18658911, -0.14067613,\n",
       "        0.02233459, -0.04383697, -0.03800959, -0.01643646,  0.05336574,\n",
       "        0.31364153, -0.12541655,  1.37778809,  0.07177528,  0.89055952,\n",
       "        0.32465264, -0.00544184, -0.10784624,  0.24601687, -0.2517763 ,\n",
       "       -0.13517404, -0.13758196,  0.13245122, -0.02481823, -0.15313726,\n",
       "        0.6868488 ,  0.23838861,  0.13064106, -0.02111581, -0.29153595,\n",
       "        1.50302985,  1.11757678,  0.28300099,  0.1567873 , -0.00803447,\n",
       "        0.31409728,  0.21648198,  0.21095404,  0.09383703,  0.02804776,\n",
       "       -0.36436824,  0.02027578,  0.08739296, -0.20284313, -0.37544766,\n",
       "        0.36247671, -0.44621245,  0.2258329 , -0.29848874, -0.12526476,\n",
       "        0.37057601,  0.26550801,  1.37527904, -0.81530518, -0.31231081])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=(X_train).T.dot(W_train).dot(X_train)  \n",
    "A_inv=np.linalg.inv(A)  # inverse of (X'WX)\n",
    "B=X_train.T.dot(W_train).dot(y_train) #calculate (X'WY)\n",
    "lin_reg_weight_adj_train=A_inv.dot(B)  # caluculate (X'WX)^{-1}(X'WY)\n",
    "lin_reg_weight_adj_train \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.682711383190153"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use the above model and fit into the test set and get the MSE of the LWLR model\n",
    "ytestfit=[0]*len(y_test)  \n",
    "for j in range (100):\n",
    "    ytestfit+=X_test[:,j]*lin_reg_weight_adj_train[j]\n",
    "MSElmadj=sum((ytestfit-y_test)**2)/len(y_test)\n",
    "MSElmadj\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above 2 models the LWLR has smaller MSE than original linear regression, although the train test split has randomness, we still see some improvement by the user weight adjustment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally train the linear regression model adjusted by the user weight with full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression(fit_intercept=False)\n",
    "modellm=linreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjlr={\"adj\":adj_list,\"lin_reg_weight_adj\":modellm.coef_}\n",
    "adjweight=DataFrame(data=adjlr)\n",
    "#adjweight.to_csv(\"adjsweight.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing good and bad adjected words that has great weight(influence to the stars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  (1) Linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjweight_lmsort=adjweight.sort_values(by=\"lin_reg_weight_adj\",ascending=False)\n",
    "adjweight_lmsort.to_csv(\"adjsweight.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['friendly',\n",
       " 'neverdisappointed',\n",
       " 'delicious',\n",
       " 'notbeat',\n",
       " 'great',\n",
       " 'best',\n",
       " 'neverproblem',\n",
       " 'fast']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get positive adjected words from LWLR model with the threshold 1. (Only choose those words with coeff>1)\n",
    "adjweight_lmsort=adjweight.sort_values(by=\"lin_reg_weight_adj\",ascending=False)\n",
    "adjweight_lmsortgood=adjweight_lmsort[adjweight_lmsort[\"lin_reg_weight_adj\"]>1]\n",
    "goodlm_adj=list(adjweight_lmsortgood[\"adj\"].values)\n",
    "goodlm_adj\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['notgoingback', 'nevercome', 'notready', 'neverordered', 'later',\n",
       "       'neverreally'], dtype=object)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get negative adjected words from LWLR model with the threshold -0.25. (Only choose those words with coeff<-0.25)\n",
    "adjweight_lmsortbad=adjweight_lmsort[adjweight_lmsort[\"lin_reg_weight_adj\"]<-0.25]\n",
    "badlm_adj=adjweight_lmsortbad[\"adj\"].values\n",
    "badlm_adj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine the selected postive and negative adjective words and gain the final adjective list\n",
    "final_adj_list=list(goodlm_adj)+list(badlm_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the corresponding nouns that are adjcent to the adjected words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This function help choose sentences that contain the adjective words from the final adjective list.\n",
    "def find_adj_sentence(text):\n",
    "    list1=[]\n",
    "    for i in range (len(text)):\n",
    "        list2 = []\n",
    "        for sentence in text[i]:\n",
    "            sentence=sentence.split()\n",
    "            for word in sentence:\n",
    "                if word in final_adj_list:\n",
    "                    list2.append(\" \".join(sentence))\n",
    "        list1.append(list2)\n",
    "    return list1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hands down best pizza place mentor',\n",
       "  'pizza delicious smell alone enough make drool',\n",
       "  'service staff friendly'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['way owner handled situation great']]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pizza10sent3=find_adj_sentence(pizza10sent2)\n",
    "pizza10sent3[:5] ##Show only 5 reviews after implementing the function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the corresponding nown that close to the selected adjective words in our final adjective list, make them into\n",
    "#adjective-nown or nown-adjective pair and also get the name of the restaurant that this pair comes from.\n",
    "adj_nownlist=[]\n",
    "for j in range (len(pizza10sent3)):\n",
    "    if pizza10sent3[j]==[]:\n",
    "        pass\n",
    "    else:\n",
    "        for sentence in pizza10sent3[j]:\n",
    "            tag=nltk.pos_tag(word_tokenize(sentence))\n",
    "            for i in range(len(tag)):\n",
    "                if tag[i][0] in final_adj_list:\n",
    "                    try:\n",
    "                        if tag[i+1][1] in nown_list:\n",
    "                            adj_nownlist.append((tag[i][0],tag[i+1][0],pizza10info[j][2])) \n",
    "                    except:\n",
    "                        if tag[i-1][1] in nown_list:\n",
    "                            adj_nownlist.append((tag[i-1][0],tag[i][0],pizza10info[j][2]))\n",
    "                        else:\n",
    "                            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('delicious', 'smell', \"Marco's Pizza\"),\n",
       " ('staff', 'friendly', \"Marco's Pizza\"),\n",
       " ('situation', 'great', \"Hungry Howie's Pizza\"),\n",
       " ('best', 'part', 'Little Caesars Pizza'),\n",
       " ('great', 'pizza', \"Hungry Howie's Pizza\")]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_nownlist[:5]  ##Show first 5 as example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The noun and selected adjected  words pair for pizzahut restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Only choose those pairs from pizzahut restaurant and make it into a dictionary where the keys\n",
    "## are the adjective words and the values are also dictionarys with counts of each nouns that close to the \n",
    "## adjective words\n",
    "final_adj_nown_dict_pizzahut={}\n",
    "for pair in adj_nownlist:\n",
    "    if pair[2]==\"Pizza Hut\":\n",
    "        if pair[0] in final_adj_list:\n",
    "            if pair[0] not in final_adj_nown_dict_pizzahut:\n",
    "                final_adj_nown_dict_pizzahut[pair[0]]={pair[1]:1}\n",
    "            else:\n",
    "                if pair[1] not in final_adj_nown_dict_pizzahut[pair[0]]:\n",
    "                    final_adj_nown_dict_pizzahut[pair[0]][pair[1]]=1\n",
    "                else:\n",
    "                    final_adj_nown_dict_pizzahut[pair[0]][pair[1]]+=1\n",
    "        elif pair[1] in final_adj_list:\n",
    "            if pair[1] not in final_adj_nown_dict_pizzahut:\n",
    "                final_adj_nown_dict_pizzahut[pair[1]]={pair[0]:1}\n",
    "            else:\n",
    "                if pair[0] not in final_adj_nown_dict_pizzahut[pair[1]]:\n",
    "                    final_adj_nown_dict_pizzahut[pair[1]][pair[0]]=1\n",
    "                else:\n",
    "                    final_adj_nown_dict_pizzahut[pair[1]][pair[0]]+=1\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_adj_nown_dict__pizzahut_sort={}\n",
    "for key in final_adj_nown_dict_pizzahut:\n",
    "    final_adj_nown_dict__pizzahut_sort[key]=sorted(final_adj_nown_dict_pizzahut[key].items(),key=lambda x:x[1],reverse=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pizza', 15), ('staff', 6), ('food', 5)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_adj_nown_dict__pizzahut_sort[\"delicious\"][:3]  ##Show only the first 3 nouns near to adj 'delicious' as an example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1267"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total1=0\n",
    "for i in range (len(list(final_adj_nown_dict__pizzahut_sort.values()))):\n",
    "    pizzahutnown_list=[x[1] for x in list(final_adj_nown_dict__pizzahut_sort.values())[i]]\n",
    "    total1+=sum(pizzahutnown_list)\n",
    "\n",
    "total1   ##Total number of nouns for Pizza Hut\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The noun and selected adjective word pairs for the other 9 top pizza restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_adj_nown_dict_other9pizza={}\n",
    "for pair in adj_nownlist:\n",
    "    if pair[2]!=\"Pizza Hut\":\n",
    "        if pair[0] in final_adj_list:\n",
    "            if pair[0] not in final_adj_nown_dict_other9pizza:\n",
    "                final_adj_nown_dict_other9pizza[pair[0]]={pair[1]:1}\n",
    "            else:\n",
    "                if pair[1] not in final_adj_nown_dict_other9pizza[pair[0]]:\n",
    "                    final_adj_nown_dict_other9pizza[pair[0]][pair[1]]=1\n",
    "                else:\n",
    "                    final_adj_nown_dict_other9pizza[pair[0]][pair[1]]+=1\n",
    "        elif pair[1] in final_adj_list:\n",
    "            if pair[1] not in final_adj_nown_dict_other9pizza:\n",
    "                final_adj_nown_dict_other9pizza[pair[1]]={pair[0]:1}\n",
    "            else:\n",
    "                if pair[0] not in final_adj_nown_dict_other9pizza[pair[1]]:\n",
    "                    final_adj_nown_dict_other9pizza[pair[1]][pair[0]]=1\n",
    "                else:\n",
    "                    final_adj_nown_dict_other9pizza[pair[1]][pair[0]]+=1\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_adj_nown_dict__other9pizza_sort={}\n",
    "for key in final_adj_nown_dict_other9pizza:\n",
    "    final_adj_nown_dict__other9pizza_sort[key]=sorted(final_adj_nown_dict_other9pizza[key].items(),key=lambda x:x[1],reverse=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('food', 166), ('delivery', 130), ('service', 70)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_adj_nown_dict__other9pizza_sort[\"fast\"][:3]  ##Show only the first 3 nouns near to adj 'fast' as an example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5335"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total2=0\n",
    "for i in range (len(list(final_adj_nown_dict__other9pizza_sort.values()))):\n",
    "    othernown_list=[x[1] for x in list(final_adj_nown_dict__other9pizza_sort.values())[i]]\n",
    "    total2+=sum(othernown_list)\n",
    "\n",
    "total2   ## Total number of nouns for other 9 pizza restaurants\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
